---
title: ナレッジベースの作成とドキュメントのアップロード
version: '日本語'
---

ナレッジベースを作成し、ドキュメントをアップロードする手順は大まかに以下の通りです：

1. Difyチーム内でナレッジベースを作成し、ローカルからアップロードするドキュメントを選びます。
2. 段落を分割し、クリーニングモードを選択します。そして、プレビューを確認します。
3. インデックス方法と検索設定を構成します。
4. 段落の埋め込みが完了するのを待ちます。
5. アップロードが完了したら、アプリ内で関連付けて使用します 🎉

ナレッジベースを作成し、文書をアップロードする手順は、以下のように大きく分けることができます：

### 1. ナレッジベースの作成

Difyのメインナビゲーションバーから「ナレッジベース」をクリックし、チーム内のナレッジベースを確認します。次に、「**ナレッジベースを作成**」をクリックしてウィザードを開始します。

- アップロードしたいファイルをドラッグアンドドロップするか、直接選択してアップロードします。一度にアップロードできるファイルの数は、[サブスクリプションプラン](https://dify.ai/pricing)に依存します。
- 文書が準備できていない場合には、空のナレッジベースを作成することも可能です。
- 外部データソース（Notionやウェブサイトとの同期）を利用してナレッジベースを作成する際には、ナレッジベースの種類を変更することはできません。これは、単一のナレッジベースに複数のデータソースが存在すると管理上の問題が生じるためです。複数のデータソースを使用する必要がある場合は、複数のナレッジベースを作成し、[リランク](../indexing-and-retrieval/rerank)モードを使って同一アプリ内で複数のナレッジベースを参照することを推奨します。

**ファイルのアップロードには以下の制限があります：**

- 1つのドキュメントのアップロードサイズは最大15MBです。

<Frame caption="ナレッジベースを作成">
  <img src="/ja-jp/images/en-upload-files-1.png" alt="" />
</Frame>

***

### 2. セクショニングとクリーニング戦略の選択

ナレッジベースにコンテンツをアップロードした後、コンテンツのセクショニングとデータクリーニングを行う必要があります。この段階では、コンテンツの前処理と構造化が重要です。

<Accordion title="セクショニングとクリーニングとは？">

* **セクショニング**
  
  大規模言語モデルは限られたコンテキストウィンドウしか持っていないため、ナレッジベース内のすべてのコンテンツを一度にLLMに送信することはできません。そのため、長いテキストをセクションに分割し、ユーザーの質問に基づいて最も関連性の高い段落をリコールする、つまりセクションごとのトップKリコールモードを採用します。ユーザーの質問とテキストセクションの意味的な一致を図るために適切なセクションサイズを用いることで、ナレッジベース内で最も関連性の高いテキストコンテンツを特定しやすくなり、情報ノイズも減少します。

* **クリーニング**

  テキストのリコール効果を確保するために、通常はデータをナレッジベースに入力する前にクリーニングを実施します。例えば、テキストコンテンツに意味のない文字や空行が含まれていると、回答の品質に悪影響を及ぼす可能性があります。Difyの組み込みクリーニング戦略の詳細については、[ETL](./upload-documents#etl)をご覧ください。

</Accordion>

以下の2つの戦略がサポートされています：

* **自動セクショニングとクリーニング**
* **カスタム**

<Tabs>

  <Tab title="自動セクショニングとクリーニング" >

    #### 自動セクショニングとクリーニング

    自動モードは、セクショニングや前処理に関する知識があまりない初心者ユーザーに適しています。このモードでは、Difyがコンテンツファイルを自動的にセクション分割し、クリーニングを行います。

    <Frame caption="自動セクショニングとクリーニング">
      <img src="/ja-jp/images/en-upload-files-2.avif" alt="Automatic segmentation and cleaning" />
    </Frame>
    
  </Tab>

  <Tab title="カスタム" >
    #### カスタム

    カスタムモードは、明確な要件を持つ上級ユーザーに最適です。このモードでは、異なるドキュメント形式やシーン要件に基づいて、テキストのセクション分割ルールとクリーニング戦略を手動で設定できます。

    **セクション分割ルール：**

    * **セクション識別子**：テキスト内で指定した識別子が出現する際にセクション分割が行われます。例えば、`\n`（[正規表現](https://regexr.com/)での改行文字）を指定すると、テキストが改行された際に自動的にセクションが分割されます。
    * **セクション最大長**：セクションのテキスト文字数が最大制限を超えると、強制的にセクションが分割されます。1つのセクションの最大長さは4000トークンです。
    * **セクションオーバーラップ長**：データをセクションに分割する際に、セクション間に一定のオーバーラップ部分が存在します。このオーバーラップは情報の保持や分析の正確性を向上させ、リコール効果を高めるのに役立ちます。セクション長のトークン数の10-25%に設定することが推奨されます。

    **テキスト前処理ルール**：ナレッジベース内の一部の意味のないコンテンツをフィルタリングするのに役立ちます。

    * 連続する空白、改行、タブを置換します。
    * すべてのURLと電子メールアドレスを削除します。

    <Frame caption="カスタムセクショニングとクリーニング">
      <img src="/ja-jp/images/en-upload-files-3.webp" alt="Custom segmentation and cleaning" />
    </Frame>
  </Tab>
</Tabs>

## 3 インデックス方法

コンテンツの前処理方法（セグメンテーションとクリーニング）を指定した後、次に構造化コンテンツのインデックス方法を指定する必要があります。インデックス方法は、LLMがナレッジベースのコンテンツを検索する効率と回答の正確性に直接影響を与えます。

システムは以下の3つのインデックス方法を提供しており、各方法内の[検索設定](./upload-documents#)を調整することができます：

- 高品質
- コスト効率
 
<Tabs>
  <Tab title="高品質" >
    高品質モードでは、セグメンテーションされたテキストを数値ベクトルに変換する埋め込みモデル（切り替え可能）を最初に呼び出し、開発者が大量のテキスト情報を効果的に圧縮および保存するのを支援します。また、ユーザーとLLMの対話時により高い精度を提供することも可能です。
    高品質インデックス方法には、ベクトル検索、全文検索、ハイブリッド検索の3つの検索設定が提供されています。詳細な検索設定については、[検索設定](./upload-documents#)をご覧ください。
    <Frame caption="高品質モード">
      <img src="/ja-jp/images/en-upload-files-4.webp" alt="" />
    </Frame>
  </Tab>

  <Tab title="コスト効率" >
    オフラインのベクトルエンジンとキーワードインデックス方式を使用し、トークンを追加コストなしで削減するが、精度が低下します。検索方式では逆インデックスのみが提供され、詳細については[後述](./upload-documents#)をご覧ください。
    <Frame caption="コスト効率モード">
      <img src="/ja-jp/images/en-upload-files-5.webp" alt="" />
    </Frame>
  </Tab>

</Tabs>

***

## 4 検索設定

**高品質インデックス方法**の下で、Difyは次の3つの検索オプションを提供しています：

- **ベクトル検索**
- **全文検索**
- **ハイブリッド検索**

<Tabs>

  <Tab title="ベクトル検索" >

    **定義：** ユーザーの入力した質問をベクトル化し、クエリベクトルとナレッジベース内の対応するテキストベクトルの距離を比較し、最も近いセグメントコンテンツを見つけます。

    <Frame caption="ベクトル検索">
      <img src="/ja-jp/images/en-upload-files-8.png" alt="" />
    </Frame>

    **ベクトル検索設定：**

    **Rerankモデル：** ベクトル検索の再呼び出し後、第三者のRerankモデルを使用してセグメントを再度意味的に並べ替え、結果を最適化します。RerankモデルのAPIキーを「モデルプロバイダー」ページで構成した後、検索設定で「Rerankモデル」をオンにします。

    **TopK：** ユーザーの質問と最も類似したテキストセグメントを選択するために使用されます。システムは同時に選択したモデルのコンテキストウィンドウサイズに基づいてセグメントの数を動的に調整します。デフォルト値は3であり、数値が高いほど、予想されるテキストセグメントの数も多くなります。

    **スコア閾値：** テキストセグメントの選択に使用する類似度の閾値を設定し、設定スコアを超えるテキストセグメントのみを返します。デフォルト値は0.5であり、数値が高いほど、テキストと質問の類似度が高く、返されるテキストの数も少なくなります。

    > TopKとスコア設定はRerankステップでのみ有効であり、これらの設定を適用するにはRerankモデルを追加してオンにする必要があります。
  
  </Tab>

  <Tab title="全文検索" >

    **定義：** キーワード検索、つまり文書内のすべての単語をインデックスします。ユーザーが質問を入力すると、ナレッジベース内の対応するテキストセグメントに明示的なキーワードマッチングを行い、キーワードに一致するテキストセグメントを返します。これは、検索エンジンのキーワード検索に類似しています。

    <Frame caption="全文检索">
      <img src="/ja-jp/images/en-upload-files-9.png" alt="" />
    </Frame>

    **Rerank モデル：** 全文検索で取得したセグメントに対して、サードパーティの Rerank モデルを使用して再評価し、意味に基づいて結果を最適化します。まず、"モデルサプライヤー" ページで Rerank モデルの API キーを設定し、その後、検索設定で "Rerank モデル" をオンにしてください。

    **TopK：** ユーザーの問いに最も似たテキストセグメントを選ぶために利用されます。システムは選択されたモデルのコンテキストウィンドウサイズに基づいて、取得するセグメントの数を動的に調整します。デフォルト値は3で、この値を大きくするほど、取得されるテキストセグメントの数が増えます。

    **スコア閾値：** テキストセグメントの選択における類似度の閾値を設定します。設定したスコアを超えるテキストセグメントのみが取得されます。デフォルト値は0.5です。値が高いほど、テキストと問いの類似性が高まり、取得されるテキストの数は減少します。

    > Rerank ステップでのみ TopK とスコアの設定が有効になるため、これらの設定を適用するには Rerank モデルを追加して有効にする必要があります。

  </Tab>

  <Tab title="ハイブリッド検索" >
    **定义：** 定義： 全文検索とベクトル検索を同時に実行し、リランクステップを適用して、2種類のクエリ結果からユーザーの質問に最も適した結果を選びます。このモードでは、「重み設定」を指定するか、Rerank モデルを選択して検索できます。

    <Frame caption="混合检索">
      <img src="/ja-jp/images/en-upload-files-10.png" alt="" />
    </Frame>

    ハイブリッド検索の設定では、**「重み設定」** または **「Rerankモデル」** を有効にすることが可能です。

    **重み設定: ** ユーザーは、意味とキーワードの優先順位を反映したカスタムの重みを設定できます。キーワード検索はナレッジベース内のフルテキスト検索を指し、意味検索はナレッジベース内のベクトル検索を指します。

    * **意味値が1の場合**

    意味検索モードのみが有効になります。埋め込みモデルを利用することで、ナレッジベースにクエリ内の正確な用語が存在しなくても、ベクトル距離を計算し、検索の深さを向上させることで正しいコンテンツを返します。また、複数の言語のコンテンツを扱う必要がある場合、意味検索は異なる言語間の意味変換を捉え、より正確なクロス言語検索結果を提供します。

    * **キーワード値が1の場合**

    キーワード検索モードのみが有効になります。ユーザーが入力した情報テキストをナレッジベース内でフルテキスト一致させるため、正確な情報や用語を知っている場合に適しています。この方法は、比較的少ない計算リソースで、大量の文書を持つナレッジベース内での迅速な検索を実現します。

    * **カスタムキーワードと意味のウェイト**

    意味検索またはキーワード検索モードを有効にするだけでなく、柔軟なカスタム重み設定も提供しています。両方の重みを調整することで、ビジネスシナリオに最適な重み比率を見つけ出すことができます。



    ***

    **Rerankモデル:** 「モデル・プロバイダー」ページでRerankモデルのAPIキーを構成した後、検索設定で「Rerankモデル」をオンにすると、システムはハイブリッド検索後に再度呼び出されたドキュメント結果を意味的に再ソートし、結果を最適化します。

    ***

    **「重み設定」** と **「Rerankモデル」** の設定では、以下のオプションを有効にすることができます：

    **TopK：** ユーザーの問い合わせに最も類似したテキスト断片を選択するために使用されます。システムは選択されたモデルのコンテキストウィンドウのサイズに応じて断片の数を動的に調整します。システムのデフォルト値は3で、値が大きいほど、期待される召回されるテキスト断片の数が増えます。

    **スコア閾値：**テキスト断片の選択に使用される類似度の閾値を設定します。つまり、設定されたスコアを超えるテキスト断片のみを呼び出します。システムのデフォルトでは、この設定はオフになっており、召回されるテキスト断片の類似性をフィルタリングしません。オンにすると、デフォルト値は0.5になり、数値が大きいほど期待される召回されるテキストの数が少なくなります。
  
  </Tab>

 </Tabs>

***

**経済インデックス方式**では、Difyは1つの検索設定のみを提供しています：

#### **転置インデックス**

転置インデックスは、文書内のキーワードを迅速に検索するための索引構造であり、その基本原理は文書中のキーワードを含む文書リストにマッピングすることで、検索効率を向上させることです。詳細な原理については、[転置インデックス](https://ja.wikipedia.org/wiki/%E8%BB%A2%E7%BD%AE%E3%82%A4%E3%83%B3%E3%83%87%E3%83%83%E3%82%AF%E3%82%B9)を参照してください。

**TopK：** ユーザーの質問に最も類似したテキスト断片を選択するために使用されます。システムは、選択されたモデルのコンテキストウィンドウサイズに基づいて、断片の数を動的に調整します。システムのデフォルト値は3です。数値が高いほど、期待されるテキスト断片の数が多く取得されます。

<Frame caption="転置インデックス">
  <img src="/ja-jp/images/en-upload-files-8.png" alt="" />
</Frame>

検索設定を指定した後、[リコールテスト/引用の帰属](../retrieval-test-and-citation)を参照して、キーワードとコンテンツブロックの一致状況を確認できます。

## 5 アップロードを完了する

上記の設定を行った後、「保存して処理」をタップするとナレッジベースの作成が完了します。 [アプリケーション内でナレッジ ベースを統合する](../integrate-knowledge-within-application) を参照して、ナレッジ ベースに基づいて Q&A を実行できる LLM アプリケーションを構築できます。

***

## 参考読書

#### ETL

RAGの生産環境においては、より良いデータ取得の効果を得るために、複数のソースからのデータを前処理およびクリーンアップする必要があります。これはETL（_extract, transform, load_）のことを指します。非構造化および半構造化データの前処理能力を強化するために、DifyはオプションのETLソリューションを提供しています：**Dify ETL** と [**Unstructured ETL**](https://unstructured.io/)です。

> Unstructuredは、効率よくデータを抽出し変換し、次のステップで使用できるクリーンなデータを提供します。Difyの各バージョンのETLソリューションの選択肢：

ファイル解析のサポート形式の違い：

| DIFY ETL                                       | Unstructured ETL                                                         |
| ---------------------------------------------- | ------------------------------------------------------------------------ |
| txt、markdown、md、pdf、html、htm、xlsx、xls、docx、csv | txt、markdown、md、pdf、html、htm、xlsx、xls、docx、csv、eml、msg、pptx、ppt、xml、epub |

<Info>異なるETLソリューションは、ファイルの抽出効果においても差異があります。Unstructured ETLのデータ処理方法について詳しく知りたい場合は、[公式ドキュメント](https://docs.unstructured.io/open-source/core-functionality/partitioning)をご覧ください。</Info>

**Embedding モデル**

**Embedding技術**は、離散的な変数（単語、文、または全文書など）を連続的なベクトル表現に変換する技術です。これにより、高次元データ（単語、フレーズ、または画像など）を低次元空間にマッピングし、コンパクトで効果的な表現を提供します。この表現はデータの次元を減少させるだけでなく、重要な意味情報を保持し、後続のコンテンツ検索をより効率的に行えるようにします。

**Embeddingモデル**は、テキストをベクトル化するために特化した大規模言語モデルであり、文を密な数値ベクトルに変換し、意味情報を効果的に捉えることが得意です。
